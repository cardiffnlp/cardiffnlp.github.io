@inproceedings{vasquez-rodriguez-etal-2022-benchmark,
 abstract = {We release a new benchmark for Automated Readability Assessment (ARA) of texts in Spanish. We combined existing corpora with suitable texts collected from the Web, thus creating the largest available dataset for ARA of Spanish texts. All data was pre-processed and categorised to allow experimenting with ARA models that make predictions at two (simple and complex) or three (basic, intermediate, and advanced) readability levels, and at two text granularities (paragraphs and sentences). An analysis based on readability indices shows that our proposed datasets groupings are suitable for their designated readability level. We use our benchmark to train neural ARA models based on BERT in zero-shot, few-shot, and cross-lingual settings. Results show that either a monolingual or multilingual pre-trained model can achieve good results when fine-tuned in language-specific data. In addition, all mod- els decrease their performance when predicting three classes instead of two, showing opportunities for the development of better ARA models for Spanish with existing resources.},
 address = {Abu Dhabi, United Arab Emirates (Virtual)},
 author = {Vásquez-Rodrı́guez, Laura  and
Cuenca-Jiménez, Pedro-Manuel  and
Morales-Esquivel, Sergio  and
Alva-Manchego, Fernando},
 booktitle = {Proceedings of the Workshop on Text Simplification, Accessibility, and Readability (TSAR-2022)},
 month = {December},
 pages = {188--198},
 publisher = {Association for Computational Linguistics},
 title = {A Benchmark for Neural Readability Assessment of Texts in Spanish},
 url = {https://aclanthology.org/2022.tsar-1.18},
 year = {2022}
}

